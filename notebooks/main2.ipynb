{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a7af76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SignId to ShapeId is a function!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def load_info():\n",
    "    SignId_to_ShapeId,ClassId_to_SignId={},{}\n",
    "    df=pd.read_csv(\"data/Meta.csv\")\n",
    "    df=df[[\"ClassId\",\"ShapeId\",\"SignId\"]]\n",
    "    df_filled = df.fillna(\"0\")\n",
    "    for row in df_filled.itertuples():\n",
    "        ClassId_to_SignId[row.ClassId]=row.SignId\n",
    "        if row.SignId not in SignId_to_ShapeId:\n",
    "            SignId_to_ShapeId[row.SignId]=row.ShapeId\n",
    "        else:\n",
    "            if SignId_to_ShapeId[row.SignId]!=row.ShapeId:\n",
    "                print(\"SignId to ShapeId is not a function!\")\n",
    "    print(\"SignId to ShapeId is a function!\")\n",
    "    return (SignId_to_ShapeId,ClassId_to_SignId)\n",
    "\n",
    "SignId_to_ShapeId,ClassId_to_SignId=load_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84e3032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "IMG_WIDTH=30\n",
    "IMG_HEIGHT=30\n",
    "\n",
    "# a method suitable for both train data and test data loading\n",
    "\n",
    "def load_data(data_dir, csv_file_path):\n",
    "    images,labels=[],[]\n",
    "    df=pd.read_csv(csv_file_path)\n",
    "    df=df[[\"ClassId\",\"Path\"]]\n",
    "    for row in df.itertuples():\n",
    "        image_path=os.path.join(data_dir, row.Path)\n",
    "        image = cv2.imread(image_path)\n",
    "        resized_image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "        images.append(resized_image)\n",
    "        labels.append(int(ClassId_to_SignId[row.ClassId]))\n",
    "        '''print(images)\n",
    "        print(type(images[0]))\n",
    "        print(images[0].shape)\n",
    "        print(labels)'''\n",
    "    print(\"Data loaded\")\n",
    "    return (images,labels)\n",
    "\n",
    "# loading the test and training data\n",
    "def load_train_and_test_data(data_dir):\n",
    "    train,test=\"Train.csv\",\"Test.csv\"\n",
    "    files=set([f for f in os.listdir(data_dir)])\n",
    "    if test in files:\n",
    "        test_label_path=os.path.join(data_dir,test)\n",
    "        x_train,y_train=load_data(data_dir,test_label_path)\n",
    "    else:\n",
    "        raise Exception(\"Test labels are not available\")\n",
    "    if train in files:\n",
    "        train_label_path=os.path.join(data_dir,train)\n",
    "        x_test,y_test=load_data(data_dir,train_label_path)\n",
    "    else:\n",
    "        raise Exception(\"Training labels are not available\")\n",
    "    return (x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4466423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def data_preprocessing(x_train,x_test):\n",
    "    # mean subtraction and normalization\n",
    "    mean = np.mean(x_train, axis=0)\n",
    "    std = np.std(x_train, axis=0)\n",
    "    x_train = (x_train - mean) / std\n",
    "    x_test = (x_test - mean) / std\n",
    "    print(\"Data preprocessing completed.\")\n",
    "    return (x_train,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7870ee18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n",
      "Data loaded\n",
      "Data preprocessing completed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "from model_training import get_model\n",
    "from data_preprocessing import data_preprocessing\n",
    "from data_loading import load_train_and_test_data\n",
    "\n",
    "EPOCHS = 10\n",
    "num_of_categories=43\n",
    "IMG_WIDTH=30\n",
    "IMG_HEIGHT=30\n",
    "\n",
    "# load the train and test data\n",
    "x_train, y_train, x_test, y_test = load_train_and_test_data(\"data\")\n",
    "x_train, y_train, x_test, y_test = np.array(x_train), np.array(y_train), np.array(x_test), np.array(y_test)\n",
    "# one hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "x_train, x_test=data_preprocessing(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b522805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "num_of_categories=43\n",
    "IMG_WIDTH=30\n",
    "IMG_HEIGHT=30\n",
    "regularizer_strength=0.3\n",
    "dropout_rate=0.3\n",
    "def get_model(optimizer):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(regularizer_strength), input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(regularizer_strength), kernel_initializer='he_normal'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\", kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(regularizer_strength)),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.BatchNormalization(), \n",
    "        tf.keras.layers.Dense(num_of_categories, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=optimizer,  \n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    print(\"Model trained.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cb2b4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained.\n",
      "Epoch 1/10\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 241ms/step - accuracy: 0.4937 - loss: 37.8236\n",
      "Epoch 2/10\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 166ms/step - accuracy: 0.6924 - loss: 5.1687\n",
      "Epoch 3/10\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 243ms/step - accuracy: 0.7568 - loss: 3.6989\n",
      "Epoch 4/10\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 211ms/step - accuracy: 0.8050 - loss: 2.7798\n",
      "Epoch 5/10\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 237ms/step - accuracy: 0.8331 - loss: 2.2542\n",
      "Epoch 6/10\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 238ms/step - accuracy: 0.8506 - loss: 1.9856\n",
      "Epoch 7/10\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 222ms/step - accuracy: 0.8539 - loss: 1.7893\n",
      "Epoch 8/10\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 181ms/step - accuracy: 0.8757 - loss: 1.5527\n",
      "Epoch 9/10\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 198ms/step - accuracy: 0.8657 - loss: 1.5399\n",
      "Epoch 10/10\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 206ms/step - accuracy: 0.8795 - loss: 1.4292\n",
      "1226/1226 - 67s - 54ms/step - accuracy: 0.7757 - loss: 1.7374\n",
      "the accuracy with nadam optimizer is  0.7757147550582886\n",
      "Model trained.\n",
      "Epoch 1/10\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 153ms/step - accuracy: 0.5336 - loss: 41.7597\n",
      "Epoch 2/10\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 171ms/step - accuracy: 0.7127 - loss: 5.0996\n",
      "Epoch 3/10\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 179ms/step - accuracy: 0.7743 - loss: 3.7232\n",
      "Epoch 4/10\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 204ms/step - accuracy: 0.8136 - loss: 2.7834\n",
      "Epoch 5/10\n",
      "\u001b[1m173/395\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 187ms/step - accuracy: 0.8442 - loss: 2.3280"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# evaluate the nadam performance, expected to be close to the above\u001b[39;00m\n\u001b[32m     11\u001b[39m model = get_model(\u001b[33m\"\u001b[39m\u001b[33mnadam\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m loss,accuracy = model.evaluate(x_test, y_test, verbose=\u001b[32m2\u001b[39m, batch_size=\u001b[32m32\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mthe accuracy with adam optimizer is \u001b[39m\u001b[33m\"\u001b[39m, accuracy)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\smile\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:3052\u001b[39m, in \u001b[36mInteractiveShell._tee.<locals>.write\u001b[39m\u001b[34m(data, *args, **kwargs)\u001b[39m\n\u001b[32m   3047\u001b[39m     output_stream = HistoryOutput(\n\u001b[32m   3048\u001b[39m         output_type=output_type, bundle={\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m   3049\u001b[39m     )\n\u001b[32m   3050\u001b[39m     outputs_by_counter[execution_count].append(output_stream)\n\u001b[32m-> \u001b[39m\u001b[32m3052\u001b[39m \u001b[43moutput_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbundle\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m  \u001b[38;5;66;03m# Append to existing stream\u001b[39;00m\n\u001b[32m   3053\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[31mMemoryError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# evaluate the adam performance\n",
    "model = get_model(\"adam\")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=EPOCHS, batch_size=32)\n",
    "\n",
    "loss,accuracy = model.evaluate(x_test, y_test, verbose=2, batch_size=32)\n",
    "\n",
    "print(\"the accuracy with nadam optimizer is \", accuracy)\n",
    "\n",
    "# evaluate the nadam performance, expected to be close to the above\n",
    "model = get_model(\"nadam\")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=EPOCHS, batch_size=32)\n",
    "\n",
    "loss,accuracy = model.evaluate(x_test, y_test, verbose=2, batch_size=32)\n",
    "\n",
    "print(\"the accuracy with adam optimizer is \", accuracy)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
